# Create Test Cases in Suite from Feature Ticket

## Purpose
Automatically generate comprehensive test cases in Azure DevOps by analyzing a feature ticket, its specifications, user stories, existing MQA tests, and automation code.

## Required Inputs
1. **Feature Ticket ID** (Azure DevOps Work Item ID)
2. **Test Suite ID** (Target suite where test cases will be created)

## Optional Inputs
3. **Related MQA Simple Test** (URL to existing test plan/suite)
4. **Cypress/AQA Automation** (URL to automation code repository)

## Process

### Step 1: Gather Information
Use the DevOps MCP tool to retrieve feature ticket details:
```javascript
mcp_devops-mcp_getWorkItem({
  id: [Feature Ticket ID]
})
```

Parse the description to extract:
- Specifications URL (wiki link)
- Related user story ID/URL
- Related MQA simple test URL (if present)
- Cypress for AQA URL (if present)

### Step 2: Analyze Feature Components
Extract from the feature ticket description:
- **Specifications**: Navigate to the wiki page to understand detailed requirements
- **Related User Story**: Use MCP tool to retrieve the user story work item:
  ```javascript
  mcp_devops-mcp_getWorkItem({
    id: [User Story ID]
  })
  ```
- **MQA Simple Test**: If provided, use MCP tool to get test suite information:
  ```javascript
  mcp_devops-mcp_getTestSuite({
    planId: [Plan ID],
    suiteId: [Suite ID]
  })
  ```
- **Cypress Automation**: If provided, review the automation code to understand test scenarios already implemented

### Step 3: Identify Test Scenarios
Based on the gathered information, identify:
- Functional test scenarios from specifications
- User acceptance criteria from user story
- Edge cases and negative scenarios
- Cross-browser/device compatibility needs
- Data variations (if parameters are needed)

### Step 4: Generate Test Cases
For each identified test scenario, create a test case with:

**Test Case Structure:**
```json
{
  "project": "RoyalCaninSitecore",
  "type": "Test Case",
  "fields": {
    "System.Title": "[Functionality description] - [Device/Context]",
    "System.AreaPath": "[Same as Feature Ticket]",
    "System.IterationPath": "[Same as Feature Ticket]",
    "Microsoft.VSTS.Common.Priority": 2,
    "Microsoft.VSTS.TCM.AutomationStatus": "Not Automated"
  }
}
```

**Important: NRT Test Domain**
- All NRT (Non-Regression Testing) test cases and test parameters should use the **staging domain**: `https://staging.royalcanin.com`
- Example: `https://staging.royalcanin.com/us` (not int.staging or other variants)
- This applies to all markets being tested

**Test Steps Format (XML Structure):**
Each test case should have steps in Azure DevOps XML format:
```xml
<steps id="0" last="[number of steps]">
  <step id="1" type="ValidateStep">
    <parameterizedString isformatted="true">
      &lt;DIV&gt;&lt;P&gt;[Action to perform]&lt;/P&gt;&lt;/DIV&gt;
    </parameterizedString>
    <parameterizedString isformatted="true">
      &lt;DIV&gt;&lt;P&gt;[Expected Result]&lt;/P&gt;&lt;/DIV&gt;
    </parameterizedString>
    <description/>
  </step>
  <!-- Additional steps... -->
</steps>
```

**Step Types:**
- **ValidateStep**: For verification actions (most common)
- **ActionStep**: For setup or navigation actions (use sparingly)

**HTML Formatting in Steps:**
- Use `&lt;` and `&gt;` for HTML tags (encoded)
- Wrap content in `<DIV><P>` tags for proper formatting
- Use `<BR/>` for line breaks within paragraphs
- Use `<SPAN>` with inline styles for emphasis when needed

### Step 5: Create Test Cases with Parameters
Use the MCP tool `createWorkItems` to create each test case:
```javascript
mcp_devops-mcp_createWorkItems({
  project: "RoyalCaninSitecore",
  type: "Test Case",
  fields: {
    "System.Title": "[Functionality description] - [Device/Context]",
    "System.AreaPath": "[Same as Feature Ticket]",
    "System.IterationPath": "[Same as Feature Ticket]",
    "Microsoft.VSTS.Common.Priority": 2,
    "Microsoft.VSTS.TCM.AutomationStatus": "Not Automated",
    "Microsoft.VSTS.TCM.Steps": "[XML formatted steps]"
  }
})
```

Include:
1. Descriptive title that reflects the test scenario
2. Clear test steps in Azure DevOps XML format
3. Parameters for data-driven scenarios (e.g., markets, user types, browsers)
4. Proper linkage to:
   - Feature ticket (as Related)
   - User story (as Tests)

### Step 6: Associate Test Cases with Test Suite
After all test cases are created:
1. Collect all created test case IDs
2. Use the MCP tool `addTestCasesToSuite` with the following parameters:
   - **planId**: The Test Plan ID (e.g., 552002)
   - **suiteId**: The Test Suite ID from input
   - **testCaseIds**: Array of all created test case IDs

**Example:**
```javascript
mcp_devops-mcp_addTestCasesToSuite({
  planId: 552002,
  suiteId: 957589,
  testCaseIds: [1240969, 1240968, 1240966, 1240967]
})
```

This will:
- Associate all test cases with the specified test suite
- Automatically create test configurations (Mobile/Desktop + Browser combinations)
- Assign the test cases to the appropriate tester

## Example Description Format
```
Feature: B2B Entries

specifications: 
https://dev.azure.com/MarsDevTeam/RoyalCaninSitecore/_wiki/wikis/RoyalCaninSitecore.wiki/16094/%E2%9C%85-p028_u-B2B-entries

related user story: 
https://dev.azure.com/MarsDevTeam/RoyalCaninSitecore/_workitems/edit/464203

related MQA simple test: 
https://dev.azure.com/MarsDevTeam/RoyalCaninSitecore/_testPlans/define?planId=552002&suiteId=957589

cypress for AQA: 
https://dev.azure.com/MarsDevTeam/RoyalCaninSitecore/_git/Websites.RoyalCanin.UpgradeAutomationTestsGit?path=/cypress/e2e/B2BEntries.feature&version=GBdevelop
```

## Output
- Summary of test cases created with IDs
- List of test scenarios covered
- Confirmation of test suite association (with test case IDs added)
- Test configurations created (Mobile/Desktop + Browser combinations)
- Any gaps or additional scenarios recommended

## Best Practices (Based on Suite 552008 Analysis)

### Naming Conventions
- **Format**: "Check [functionality] - [Device/Platform]"
- **Examples**: 
  - "Check the header - mobile"
  - "Check country selector - Mobile"
  - "Check B2B entries - Desktop"

### Test Step Structure Patterns
1. **Initial Verification Steps**: Start with checking element availability
   - Example: "Verify the section is available on all pages of the site"
   - Example: "Check that country/language selector is available both in burger menu and Footer"

2. **Navigation/Action Steps**: Describe user actions clearly
   - Use "Navigate to...", "Click on...", "Scroll down...", "Tap..."
   - Be specific about element names and locations

3. **Expected Results**: Should be clear, measurable, and specific
   - Example: "Burger menu, Logo, Search, and My Account icons are displayed at the top"
   - Example: "Panel with location and language dropdowns is displayed"
   - Include conditional expectations: "On D2C markets also cart icon should be displayed"

4. **Multiple Verifications**: Chain related validations in single steps
   - Example: "The header is sticky to the top, and the logo is animated to minimal version with Crown"

5. **State Changes**: Verify behavior changes across different contexts
   - Example: "Application is reloaded and locale is changed to the selected country and page path is still the same"

### Step Organization
- **Step Count**: Typically 3-6 steps per test case (from examples: 3 steps and 6 steps)
- **Sequential Flow**: Follow natural user journey
- **Mix Step Types**: Use ActionStep for setup, ValidateStep for verification
- **Closure**: Include cleanup/closure verification when applicable

### Device-Specific Considerations
- **Mobile Tests**: Focus on touch interactions ("Tap"), responsive elements, burger menu
- **Desktop Tests**: Focus on mouse interactions ("Click"), hover states, full navigation
- **Both Platforms**: Verify consistent functionality across devices

### Priority & Automation
- **Priority**: Default to 2 (standard priority)
- **Automation Status**: "Not Automated" by default (update later if automated)
- **State**: "Design" for new test cases

### Content Formatting
- Use HTML entities in XML (`&lt;`, `&gt;`, `&amp;`)
- Maintain consistent spacing and line breaks
- Use SPAN tags with styles for visual emphasis when needed
- Keep descriptions clear and concise without excessive formatting

## Test Case Categories to Consider
1. **UI Component Verification**: Check element presence, positioning, and availability
2. **User Interaction**: Click, tap, scroll, navigation actions
3. **State Management**: Sticky headers, animations, panel open/close
4. **Navigation**: Redirects, page transitions, route preservation
5. **Responsive Behavior**: Different behaviors on mobile vs desktop
6. **Localization**: Country/language selection, locale-specific features
7. **Market-Specific Features**: D2C vs B2B differences, regional variations
8. **Integration Points**: Cross-component interactions (header, footer, menus)

## Real Examples from Suite 552008

### Example 1: Test Case 552121 - "Check the header - mobile"
**Covers**:
- Element availability across all pages
- Icon display (Burger menu, Logo, Search, My Account, Cart)
- Sticky header behavior on scroll
- Logo animation to minimal version
- Logo click navigation to home
- Country selector in hamburger menu
- Panel open/close without changes

**Pattern**: Comprehensive UI component test with multiple interaction points

**Test URL Format**: Use `https://staging.royalcanin.com/[market]` for all NRT tests

### Example 2: Test Case 957609 - "Check country selector - Mobile"
**Covers**:
- Country/language selector availability in multiple locations
- Panel display with correct locale values
- Country/language switching
- Page reload and route preservation

**Pattern**: Focused interaction test with state verification

## Technical Implementation Notes

### Azure DevOps XML Format
The `Microsoft.VSTS.TCM.Steps` field must contain properly escaped XML:
```xml
<steps id="0" last="3">
  <step id="1" type="ValidateStep">
    <parameterizedString isformatted="true">
      &lt;SPAN style="color: rgba(0, 0, 0, 0.9);background-color: rgb(239, 246, 252)"&gt;Action text&lt;/SPAN&gt;
    </parameterizedString>
    <parameterizedString isformatted="true">
      &lt;SPAN style="color: rgba(0, 0, 0, 0.9);background-color: rgb(239, 246, 252)"&gt;Expected result&lt;/SPAN&gt;
    </parameterizedString>
    <description/>
  </step>
</steps>
```

### Common HTML Patterns Observed
- **Simple Text**: `&lt;DIV&gt;&lt;P&gt;Text here&lt;/P&gt;&lt;/DIV&gt;`
- **With Line Breaks**: `&lt;P&gt;Line 1&lt;BR/&gt;Line 2&lt;/P&gt;`
- **With Styling**: `&lt;SPAN style="color: rgba(0, 0, 0, 0.9);background-color: rgb(239, 246, 252)"&gt;Text&lt;/SPAN&gt;`
- **Empty Paragraph**: `&lt;DIV&gt;&lt;P&gt;&lt;BR/&gt;&lt;/P&gt;&lt;/DIV&gt;` (for spacing)

### Step ID Sequencing
- Steps are not always sequential (e.g., id="2", id="3", id="4"... or id="1", id="2", id="3")
- The `last` attribute in `<steps>` should match the highest step ID
- IDs should be unique within the test case

### Field Multiline Format
Set `multilineFieldsFormat` to indicate HTML formatting:
```json
"multilineFieldsFormat": {
  "Microsoft.VSTS.TCM.Steps": "html"
}
```
